{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import  re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel,cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chestnut Ridge Middle School</td>\n",
       "      <td>8554860</td>\n",
       "      <td>#REDIRECT[[Washington Township Public School D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colegio de Santa Cruz de Tlatelolco</td>\n",
       "      <td>8554864</td>\n",
       "      <td>{{Infobox university\\n|name              = Col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Template:US-gov-bio-stub</td>\n",
       "      <td>8554865</td>\n",
       "      <td>{{asbox\\n| image     = Great Seal of the Unite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Impractical joker (garfield)</td>\n",
       "      <td>8554867</td>\n",
       "      <td>#REDIRECT [[List of Garfield and Friends episo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>File:The Imperial Dowager Empress Yehenara.PNG</td>\n",
       "      <td>8554869</td>\n",
       "      <td>== Summary ==\\nhttp://guangxu.netor.com/galler...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Title       ID  \\\n",
       "0                    Chestnut Ridge Middle School  8554860   \n",
       "1             Colegio de Santa Cruz de Tlatelolco  8554864   \n",
       "2                        Template:US-gov-bio-stub  8554865   \n",
       "3                    Impractical joker (garfield)  8554867   \n",
       "4  File:The Imperial Dowager Empress Yehenara.PNG  8554869   \n",
       "\n",
       "                                                Text  \n",
       "0  #REDIRECT[[Washington Township Public School D...  \n",
       "1  {{Infobox university\\n|name              = Col...  \n",
       "2  {{asbox\\n| image     = Great Seal of the Unite...  \n",
       "3  #REDIRECT [[List of Garfield and Friends episo...  \n",
       "4  == Summary ==\\nhttp://guangxu.netor.com/galler...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tree = ET.parse('enwiki-20210101-pages-articles-multistream12.xml-p8554860p9172788')\n",
    "root = tree.getroot()\n",
    "\n",
    "titles = []\n",
    "texts = []\n",
    "ids = []\n",
    "\n",
    "ns = {'mediawiki': 'http://www.mediawiki.org/xml/export-0.10/'}\n",
    "for child in root.findall('mediawiki:page', ns):\n",
    "    title = child.find('mediawiki:title', ns)\n",
    "    identifier = child.find('mediawiki:id', ns)\n",
    "    titles.append(title.text)\n",
    "    ids.append(identifier.text)\n",
    "    for revision in child.findall('mediawiki:revision', ns):\n",
    "        text_data = revision.find('mediawiki:text', ns)\n",
    "        if text_data != None:\n",
    "            texts.append(text_data.text)\n",
    "        else:\n",
    "            texts.append(None)\n",
    "\n",
    "            # Create data frame with elements\n",
    "\n",
    "dataframe = pd.DataFrame(data={'Title': titles, 'ID': ids, 'Text': texts})\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data\n",
    "\n",
    "<ol>    \n",
    "    <li> Remove tags like</li>\n",
    "\n",
    "    <li>Remove Urls</li>\n",
    "    \n",
    "    <li>Remove Punctuations</li>\n",
    "    \n",
    "    <li>Remove stop words</li>\n",
    "    \n",
    "    <li>Remove numbers</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove html tags \n",
    "def tags_Rem(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext\n",
    "#Remove urls\n",
    "def url_Rem(text):\n",
    "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', text, flags=re.MULTILINE)\n",
    "    return text\n",
    "#Remove punctuations \n",
    "#THis function takes a string as input, removes the punctuation and return it back \n",
    "def Rem_Punc(text):\n",
    "        text = re.sub(r'[^\\w\\s]','',text)\n",
    "        return text\n",
    "##Remove \\n\n",
    "def newline_remove(text):\n",
    "    text.replace('\\n', '')\n",
    "    return text##remove stop words \n",
    "\n",
    "def stop_words(text):\n",
    "    \n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "\n",
    "    word_tokens = word_tokenize(text) \n",
    "\n",
    "    filtered_text = [w for w in word_tokens if not w in stop_words] \n",
    "\n",
    "    filtered_text = \"\"\n",
    "\n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_text = filtered_text + \" \"+w\n",
    "    return filtered_text\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    text = tags_Rem(text)\n",
    "    text = url_Rem(text)\n",
    "    text = Rem_Punc(text)\n",
    "    text = newline_remove(text)\n",
    "    text = stop_words(text)\n",
    "    return text\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### drop  empty  pages \n",
    "drop_lines = 'Portal|File|Category|JPG|PNG|jpg|Wikipedia|Template'\n",
    "dataframe = dataframe[~dataframe.Title.str.contains(drop_lines)]\n",
    "dataframe = dataframe.dropna().reset_index()\n",
    "del dataframe['index']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save the preprocessed dataset\n",
    "titles_ = []\n",
    "ids_ = []\n",
    "text_ = []\n",
    "for index, row in dataframe.iterrows():\n",
    "    #print(type(row[\"Text\"]))\n",
    "    text =pre_process( str(row[\"Text\"]))\n",
    "    text_.append(text)\n",
    "    ids_.append(row[\"ID\"])\n",
    "    titles_.append(row[\"Title\"])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read the dataset\n",
    "dataframe_processed = pd.DataFrame(data={'Title': titles_, 'ID': ids_, 'Text': text_})\n",
    "dataframe_processed.to_csv(\"processed_data\", sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD_IDF Representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words='english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data\n",
    "dataframe_processed = pd.read_csv(\"processed_data\",sep = \"\\t\") \n",
    "##reduce tha data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce the dataset \n",
    "#dataframe_processed_reduced = dataframe_processed.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        2\n",
       "3        3\n",
       "4        4\n",
       "      ... \n",
       "995    995\n",
       "996    996\n",
       "997    997\n",
       "998    998\n",
       "999    999\n",
       "Name: Unnamed: 0, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the extra column\n",
    "dataframe_processed.pop(\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comput the tfidf matrix\n",
    "tfidf_matrix = tf.fit_transform(dataframe_processed['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.01173054, 0.        , ..., 0.        , 0.        ,\n",
       "        0.00959829],\n",
       "       [0.01173054, 1.        , 0.00120294, ..., 0.        , 0.        ,\n",
       "        0.00857503],\n",
       "       [0.        , 0.00120294, 1.        , ..., 0.00778287, 0.0114735 ,\n",
       "        0.0123577 ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.00778287, ..., 1.        , 0.01734471,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.0114735 , ..., 0.01734471, 1.        ,\n",
       "        0.        ],\n",
       "       [0.00959829, 0.00857503, 0.0123577 , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in dataframe_processed.iterrows():\n",
    "    similar_indices = cosine_similarities[idx].argsort()[:-100:-1]\n",
    "    similar_items = [(cosine_similarities[idx][i], dataframe_processed['Title'][i]) for i in similar_indices]\n",
    "\n",
    "    # First item is the item itself, so remove it.\n",
    "    # Each dictionary entry is like: [(1,2), (3,4)], with each tuple being (score, item_id)\n",
    "    results[row['Title']] = similar_items[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item(id):\n",
    "    return dataframe_processed_reduced.loc[dataframe_processed['Title'] == id]['Title'].tolist()[0].split(' - ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(item_id, num):\n",
    "    print(\"Recommending \" + str(num) + \" links similar to \" + item(item_id) + \"...\")\n",
    "    print(\"-------\")\n",
    "    recs = results[item_id][:num]\n",
    "    for rec in recs:\n",
    "        print(\"Recommended: \" + 'https://en.wikipedia.org/wiki/'+item(rec[1]).replace(\" \", \"_\") + \" (score:\" + str(rec[0]) + \")\")\n",
    "        print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = input (\"Enter a wiki link: \") \n",
    "print(link[30:])\n",
    "print(link)\n",
    "string= str(link[30:]).replace(\"_\", \" \")\n",
    "#string = str(link)\n",
    "string= \"\".join([x for x in string]).split(\" \")\n",
    "string = \" \".join(string)\n",
    "string = string.lstrip()\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommending 5 products similar to Colegio de Santa Cruz de Tlatelolco...\n",
      "-------\n",
      "Recommended: Albuquerque Trivia (score:0.0666828982847375)\n",
      "========================================================\n",
      "Recommended: Ewing Young (score:0.054236226289949695)\n",
      "========================================================\n",
      "Recommended: List of points of interest in Albuquerque, New Mexico (score:0.05273692419193209)\n",
      "========================================================\n",
      "Recommended: Sisters' college (score:0.040509451026999745)\n",
      "========================================================\n",
      "Recommended: Richard John Garcia (score:0.03711085198111095)\n",
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "recommend(item_id=string, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
